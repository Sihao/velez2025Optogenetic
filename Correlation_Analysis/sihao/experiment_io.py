import pickle
import scipy.io as io
import os
import pandas as pd
import numpy as np


def load_traces(path):
    """Load segmented neuronal time traces from .pkl file

    Parameters
    ----------
    path : str
        Path to .pkl file. File is merged from the CaImAn output of each plane. File contains a
        2D array with shape (n_neurons, n_frames). The fluorescence traces of each neuron.

    Returns
    -------
    traces : array
        Array with shape (n_neurons, n_frames). The fluorescence traces of each neuron.
    """
    # Load pkl file
    with open(path, 'rb') as f:
        traces = pickle.load(f)

    return traces


def load_positions(path):
    """Load positions of neurons from .pkl file

    Parameters
    ----------
    path : str
        Path to .pkl file. File is merged from the CaImAn output of each plane. File contains a
        2D array with shape (n_neurons, 2). The x and y positions of each neuron.

    Returns
    -------
    positions : array
        Array with shape (n_neurons, 2). The x and y positions of each neuron.
    """
    # Load pkl file
    with open(path, 'rb') as f:
        positions = pickle.load(f)

    return positions


def load_stim_info(path):
    """Load stimulus information from .mat file

    Parameters
    ----------
    path : str
        Path to .mat file. File should contain a variable named 'sc'. Files are generated by the
        Opto_galvo_control.m script.

    Returns
    -------
    stim_info : array
        Array with shape (n_stimuli, 2). The columns are: the times (in seconds) at which a neuromast
        was stimulated, column 2 is the neuromast number.
    """
    # Load mat file
    stim_info = io.loadmat(path)

    # Remove keys starting with '_'
    stim_info = {key: stim_info[key] for key in stim_info.keys() if key[0] != '_'}

    # Get stimulus information
    stim_info = stim_info['sc']

    return stim_info


def load_combos_info(path):
    """Load combination information from .csv file
    File is expected to have n_stim + 1 columns, where the first column is the time of the stimulus
    and the rest are the neuromasts that were stimulated. In the columns for the individual neuromasts,
    a 1 indicates that the neuromast was stimulated and a 0 indicates that it was not at the time indicated
    in the first column.

    Parameters
    ----------
    path : str
        Path to .csv file. File should contain a column named 'neuromast' with the identities of the
        neuromasts.

    Returns
    -------
    stim_info_single : array
        Array with shape (n_stimuli_single, 2). The columns are: the times (in seconds) at which a single
        neuromast was stimulated, column 2 is the neuromast number.
    stim_info_double : array
        Array with shape (n_stimuli_double, 2). The columns are: the times (in seconds) at which a double
        neuromast was stimulated, column 2 is the neuromast number.
    stim_info_triple : array
        Array with shape (n_stimuli_triple, 2). The columns are: the times (in seconds) at which a triple
        neuromast was stimulated, column 2 is the neuromast number.
    stim_id_map : dict
        Dictionary mapping the stimulus IDs to the combination of neuromasts that were stimulated.
    """
    # Load csv, no header
    combos_info = pd.read_csv(path, header=None)

    # Cast everything except first column to bool
    combos_info.iloc[:, 1:] = combos_info.iloc[:, 1:].astype(bool)

    # Split into singles, doubles, and triples
    single_mask = combos_info.iloc[:, 1:].sum(axis=1) == 1
    double_mask = combos_info.iloc[:, 1:].sum(axis=1) == 2
    triple_mask = combos_info.iloc[:, 1:].sum(axis=1) == 3

    # Reconstruct stim_info for singles, doubles, and triples
    times = combos_info[0]
    # Consider only columns except the first one
    combos_info = combos_info.iloc[:, 1:]

    # Mask for single, double, and triple stimulations
    combos_info_single = np.argwhere(combos_info[single_mask] == True)[:, 1] + 1 # 1-indexed stimulation IDs

    combos_info_double = combos_info[double_mask]
    combos_info_triple = combos_info[triple_mask]

    # Loop over indices of dataframe to figure out unique patterns
    double_patterns = []
    triple_patterns = []

    for i in range(combos_info_double.shape[0]):
        # Get indices of True values
        d_idx = np.argwhere(combos_info_double.iloc[i, :] == True)
        # Concatenate indices as chars
        d_idx = ''.join([str(i + 1) for i in d_idx.squeeze()])
        double_patterns.append(d_idx)
    for i in range(combos_info_triple.shape[0]):
        t_idx = np.argwhere(combos_info_triple.iloc[i, :] == True)
        t_idx = ''.join([str(i + 1) for i in t_idx.squeeze()])
        triple_patterns.append(t_idx)

    # Get unique patterns
    unique_double_patterns = np.unique(double_patterns)
    unique_triple_patterns = np.unique(triple_patterns)
    # Assign unique integer to each pattern, starting from n_single
    n_single = combos_info.shape[1] + 1 # 1-indexed stimulation IDs
    unique_double_patterns = {pattern: i + n_single for i, pattern in enumerate(unique_double_patterns)}
    unique_triple_patterns = {pattern: i + n_single + len(unique_double_patterns) for i, pattern in enumerate(unique_triple_patterns)}

    # Replace patterns with integers
    double_ids  = np.zeros(combos_info_double.shape[0])
    triple_ids = np.zeros(combos_info_triple.shape[0])
    for i, pattern in enumerate(double_patterns):
        # Find corresponding new index
        id = unique_double_patterns[pattern]
        double_ids[i] = id
    for i, pattern in enumerate(triple_patterns):
        id = unique_triple_patterns[pattern]
        triple_ids[i] = id

    # Reconstruct stim_info arrays for single, double, and triple stimulations
    stim_info_single = np.concatenate([times[single_mask].values[:, None], combos_info_single[:, None]], axis=1)
    stim_info_double = np.concatenate([times[double_mask].values[:, None], double_ids[:, None]], axis=1)
    stim_info_triple = np.concatenate([times[triple_mask].values[:, None], triple_ids[:, None]], axis=1)

    # Create reference to map stimulus IDs to combinations
    stim_id_map = {i: i for i in range(1, n_single)}
    stim_id_map.update(unique_double_patterns)
    stim_id_map.update(unique_triple_patterns)

    return stim_info_single, stim_info_double, stim_info_triple, stim_id_map


def get_neuromast_identities(path):
    """Load the identities of the neuromasts from a .csv file within the experiment directory for
    a single fish. Will throw an error if the file is not found.

    Parameters
    ----------
    path : str
        Path to .csv file. File should contain a column named 'neuromast' with the identities of the
        neuromasts.

    Returns
    -------
    neuromast_identities : array
        Array with shape (n_neuromasts,). The identities of the neuromasts.
    """
    # Find csv file in directory
    # Assume filed is called neuromast_identities.csv
    path = os.path.join(path, 'neuromast_identities.csv')

    # Check if file exists
    if not os.path.exists(path):
        raise FileNotFoundError(f'No neuromast_identities.csv file found in {path}.')

    # Load csv file with comma as delimiter
    with open(path, 'r') as f:
        neuromast_identities = f.readline().strip().split(',')

    return neuromast_identities


def get_neuron_region(path):
    """Get the assigned brain region for each neuron based on .csv files in 'Regions' directory.

    Parameters
    ----------
    path : str
        Path to the main directory for the experiment. The 'Regions' directory should be a subdirectory
        of this directory.

    Returns
    -------
    neuron_regions : pandas.DataFrame
        DataFrame with the assigned brain region for each neuron. Columns are: 'idx' (neuron index),
        'region' (brain region), 'x' (x position), 'y' (y position), 'z' (z position). Positions are
        relative to registered brain atlas.
    """
    # Get path to regions directory
    path = os.path.join(path, 'Regions')

    # Get all csv files in directory
    csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]

    # Create dataframe
    neuron_regions = pd.DataFrame(columns=['neuron_idx', 'region', 'x', 'y', 'z'])

    # Loop over csv files
    for file in csv_files:
        # Get region name
        region = file.split('.')[0]

        # Skip if region name contains 'entire'
        if 'entire' in region:
            continue

        # Load csv file with comma as delimiter
        with open(os.path.join(path, file), 'r') as f:
            # Skip first row
            f.readline()
            # Get all lines until end of file
            lines = f.readlines()
            # Clean up lines
            lines = [line.strip() for line in lines]
            # Split lines by comma
            lines = [line.split(',') for line in lines]
            # Convert to int for first column and float for the rest
            lines = [[int(line[0]), float(line[1]), float(line[2]), float(line[3])] for line in lines]

            # Convert to dataframe
            lines = pd.DataFrame(lines, columns=['neuron_idx', 'x', 'y', 'z'])

            # Remove 'coords_' from region name
            region = '_'.join(region.split('_')[1:])
            # Replace spaces with underscores
            region = region.replace(' ', '_')
            lines['region'] = region

            # Assign super-region
            if 'torus' in region:
                lines['super_region'] = 'torus'
            elif 'ventral_medulla_oblongata' in region:
                lines['super_region'] = 'ventral_medulla_oblongata'
            elif 'medial_medulla_oblongata' in region:
                lines['super_region'] = 'medial_medulla_oblongata'
            elif 'dorsal_medulla_oblongata' in region:
                lines['super_region'] = 'dorsal_medulla_oblongata'
            elif 'medial_octavolateralis_nucleus' in region:
                lines['super_region'] = 'medial_octavolateralis_nucleus'
            elif 'locus_coeruleus' in region:
                lines['super_region'] = 'locus_coeruleus'

            # Assign laterality
            if 'left' in region:
                lines['laterality'] = 'left'
            elif 'right' in region:
                lines['laterality'] = 'right'
            else:
                lines['laterality'] = 'mid'

        # Append to dataframe
        neuron_regions = pd.concat([neuron_regions, lines], ignore_index=True)

    return neuron_regions